{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNn52s/0jXZ/KZVDnk0N7IM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FireGolem123/DogGait/blob/main/DOG_GAIT_PROJECT_BASE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Software Citation:\n",
        "\n",
        "@software{yolo11_ultralytics,\n",
        "  author = {Glenn Jocher and Jing Qiu},\n",
        "  title = {Ultralytics YOLO11},\n",
        "  version = {11.0.0},\n",
        "  year = {2024},\n",
        "  url = {https://github.com/ultralytics/ultralytics},\n",
        "  orcid = {0000-0001-5950-6979, 0000-0003-3783-7069},\n",
        "  license = {AGPL-3.0}\n",
        "}"
      ],
      "metadata": {
        "id": "WeniEsg-MIDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dog Data Set Citation:\n",
        "\n",
        "@inproceedings{khosla2011fgvc,\n",
        "  title={Novel dataset for Fine-Grained Image Categorization},\n",
        "  author={Aditya Khosla and Nityananda Jayadevaprakash and Bangpeng Yao and Li Fei-Fei},\n",
        "  booktitle={First Workshop on Fine-Grained Visual Categorization (FGVC), IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
        "  year={2011}\n",
        "}\n",
        "@inproceedings{deng2009imagenet,\n",
        "  title={ImageNet: A Large-Scale Hierarchical Image Database},\n",
        "  author={Jia Deng and Wei Dong and Richard Socher and Li-Jia Li and Kai Li and Li Fei-Fei},\n",
        "  booktitle={IEEE Computer Vision and Pattern Recognition (CVPR)},\n",
        "  year={2009}\n",
        "}"
      ],
      "metadata": {
        "id": "FATbQyTnwuRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install ultralytics==8.3.0\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np, cv2, ultralytics, torch\n",
        "from ultralytics import YOLO\n",
        "import urllib.request\n",
        "\n",
        "print(\"NumPy:\", np.__version__)            # expect 1.26.4\n",
        "print(\"OpenCV:\", cv2.__version__)          # expect 4.10.0.84\n",
        "print(\"Ultralytics:\", ultralytics.__version__)  # expect 8.3.0\n",
        "print(\"cuda?\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "\n",
        "# Project paths\n",
        "BASE = Path(\"/content/Dog_Gait_Demo\")\n",
        "DATA = BASE / \"data\"\n",
        "DATA.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Dataset YAML\n",
        "DOG_YAML = DATA / \"dog-pose.yaml\"\n",
        "if not DOG_YAML.exists():\n",
        "    urllib.request.urlretrieve(\n",
        "        \"https://raw.githubusercontent.com/ultralytics/ultralytics/main/ultralytics/cfg/datasets/dog-pose.yaml\",\n",
        "        DOG_YAML\n",
        "    )\n",
        "print(\"YAML:\", DOG_YAML)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI9ehbKiMLi_",
        "outputId": "a6eb3b74-a54f-4848-a0d6-b2e19d77aa4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics==8.3.0 in /usr/local/lib/python3.12/dist-packages (8.3.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.0) (2.0.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.0) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.0) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.0) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics==8.3.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics==8.3.0) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.3.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.3.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.3.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.3.0) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.0) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.3.0) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics==8.3.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.3.0) (3.0.3)\n",
            "NumPy: 1.26.4\n",
            "OpenCV: 4.11.0\n",
            "Ultralytics: 8.3.0\n",
            "cuda? True\n",
            "NVIDIA A100-SXM4-80GB\n",
            "YAML: /content/Dog_Gait_Demo/data/dog-pose.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Must be set before training\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
        "\n",
        "from ultralytics.utils import SETTINGS\n",
        "SETTINGS[\"wandb\"] = False\n",
        "print(\"Ultralytics wandb setting:\", SETTINGS.get(\"wandb\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOGmS3WgMZUs",
        "outputId": "7342a2c3-76ac-4cd1-da31-27441c9873e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics wandb setting: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use 's' for a little more capacity than 'n' without being heavy\n",
        "model = YOLO(\"yolo11s-pose.pt\")\n"
      ],
      "metadata": {
        "id": "twARnkhcMZuF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27575597-9ab8-492b-ffff-fc138eea0f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-pose.pt to 'yolo11s-pose.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19.4M/19.4M [00:00<00:00, 134MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "results = model.train(\n",
        "    data=str(DOG_YAML),\n",
        "    epochs=10,\n",
        "    imgsz=768,\n",
        "    batch=8,\n",
        "    workers=4,\n",
        "    freeze=10,\n",
        "    amp=True,\n",
        "    cache=True,\n",
        "    cos_lr=True,\n",
        "    optimizer=\"AdamW\",\n",
        "    lr0=0.001,\n",
        "    patience=80,\n",
        "    name=\"train_accuracy_boost\",\n",
        "    save_period=20,\n",
        "    device=0 if torch.cuda.is_available() else \"cpu\",\n",
        "    project=\"/content/drive/MyDrive/Dog_Gait_Demo/runs\",  # <---- auto-save all runs to Drive\n",
        "\n",
        "    # Augmentations\n",
        "    hsv_h=0.015,\n",
        "    hsv_s=0.7,\n",
        "    hsv_v=0.4,\n",
        "    translate=0.05,\n",
        "    scale=0.4,\n",
        "    fliplr=0.5,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NJfsOBlMbGS",
        "outputId": "6875e05c-0d0c-48fc-eba8-f5dfe0ceb517"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.225 available üòÉ Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.0 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=pose, mode=train, model=yolo11s-pose.pt, data=/content/Dog_Gait_Demo/data/dog-pose.yaml, epochs=10, time=None, patience=80, batch=8, imgsz=768, save=True, save_period=20, cache=True, device=0, workers=4, project=/content/drive/MyDrive/Dog_Gait_Demo/runs, name=train_accuracy_boost, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=10, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.05, scale=0.4, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/Dog_Gait_Demo/runs/train_accuracy_boost\n",
            "\n",
            "Dataset '/content/Dog_Gait_Demo/data/dog-pose.yaml' images not found ‚ö†Ô∏è, missing path '/content/datasets/dog-pose/images/val'\n",
            "Downloading https://ultralytics.com/assets/dog-pose.zip to '/content/datasets/dog-pose.zip'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 337M/337M [00:45<00:00, 7.77MB/s]\n",
            "Unzipping /content/datasets/dog-pose.zip to /content/datasets/dog-pose...: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16960/16960 [00:03<00:00, 5050.45file/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset download success ‚úÖ (49.6s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 44.9MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml kpt_shape=[17, 3] with kpt_shape=[24, 3]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
            "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
            " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
            " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
            " 23        [16, 19, 22]  1   1557003  ultralytics.nn.modules.head.Pose             [1, [24, 3], [128, 256, 512]] \n",
            "YOLO11s-pose summary: 344 layers, 10,165,387 parameters, 10,165,371 gradients, 24.3 GFLOPs\n",
            "\n",
            "Transferred 505/541 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/Dog_Gait_Demo/runs/train_accuracy_boost', view at http://localhost:6006/\n",
            "Freezing layer 'model.0.conv.weight'\n",
            "Freezing layer 'model.0.bn.weight'\n",
            "Freezing layer 'model.0.bn.bias'\n",
            "Freezing layer 'model.1.conv.weight'\n",
            "Freezing layer 'model.1.bn.weight'\n",
            "Freezing layer 'model.1.bn.bias'\n",
            "Freezing layer 'model.2.cv1.conv.weight'\n",
            "Freezing layer 'model.2.cv1.bn.weight'\n",
            "Freezing layer 'model.2.cv1.bn.bias'\n",
            "Freezing layer 'model.2.cv2.conv.weight'\n",
            "Freezing layer 'model.2.cv2.bn.weight'\n",
            "Freezing layer 'model.2.cv2.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.3.conv.weight'\n",
            "Freezing layer 'model.3.bn.weight'\n",
            "Freezing layer 'model.3.bn.bias'\n",
            "Freezing layer 'model.4.cv1.conv.weight'\n",
            "Freezing layer 'model.4.cv1.bn.weight'\n",
            "Freezing layer 'model.4.cv1.bn.bias'\n",
            "Freezing layer 'model.4.cv2.conv.weight'\n",
            "Freezing layer 'model.4.cv2.bn.weight'\n",
            "Freezing layer 'model.4.cv2.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.5.conv.weight'\n",
            "Freezing layer 'model.5.bn.weight'\n",
            "Freezing layer 'model.5.bn.bias'\n",
            "Freezing layer 'model.6.cv1.conv.weight'\n",
            "Freezing layer 'model.6.cv1.bn.weight'\n",
            "Freezing layer 'model.6.cv1.bn.bias'\n",
            "Freezing layer 'model.6.cv2.conv.weight'\n",
            "Freezing layer 'model.6.cv2.bn.weight'\n",
            "Freezing layer 'model.6.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.0.cv3.conv.weight'\n",
            "Freezing layer 'model.6.m.0.cv3.bn.weight'\n",
            "Freezing layer 'model.6.m.0.cv3.bn.bias'\n",
            "Freezing layer 'model.6.m.0.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.0.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.0.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.0.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.0.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.0.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.6.m.0.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.6.m.0.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.6.m.0.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.6.m.0.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.6.m.0.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.6.m.0.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.7.conv.weight'\n",
            "Freezing layer 'model.7.bn.weight'\n",
            "Freezing layer 'model.7.bn.bias'\n",
            "Freezing layer 'model.8.cv1.conv.weight'\n",
            "Freezing layer 'model.8.cv1.bn.weight'\n",
            "Freezing layer 'model.8.cv1.bn.bias'\n",
            "Freezing layer 'model.8.cv2.conv.weight'\n",
            "Freezing layer 'model.8.cv2.bn.weight'\n",
            "Freezing layer 'model.8.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.0.cv3.conv.weight'\n",
            "Freezing layer 'model.8.m.0.cv3.bn.weight'\n",
            "Freezing layer 'model.8.m.0.cv3.bn.bias'\n",
            "Freezing layer 'model.8.m.0.m.0.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.0.m.0.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.0.m.0.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.0.m.0.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.0.m.0.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.0.m.0.cv2.bn.bias'\n",
            "Freezing layer 'model.8.m.0.m.1.cv1.conv.weight'\n",
            "Freezing layer 'model.8.m.0.m.1.cv1.bn.weight'\n",
            "Freezing layer 'model.8.m.0.m.1.cv1.bn.bias'\n",
            "Freezing layer 'model.8.m.0.m.1.cv2.conv.weight'\n",
            "Freezing layer 'model.8.m.0.m.1.cv2.bn.weight'\n",
            "Freezing layer 'model.8.m.0.m.1.cv2.bn.bias'\n",
            "Freezing layer 'model.9.cv1.conv.weight'\n",
            "Freezing layer 'model.9.cv1.bn.weight'\n",
            "Freezing layer 'model.9.cv1.bn.bias'\n",
            "Freezing layer 'model.9.cv2.conv.weight'\n",
            "Freezing layer 'model.9.cv2.bn.weight'\n",
            "Freezing layer 'model.9.cv2.bn.bias'\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.25M/6.25M [00:00<00:00, 192MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/dog-pose/labels/train... 6773 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6773/6773 [00:06<00:00, 1024.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/dog-pose/labels/train.cache\n",
            "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (8.5GB RAM): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6773/6773 [00:03<00:00, 2251.88it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ‚ö†Ô∏è No 'flip_idx' array defined in data.yaml, setting augmentation 'fliplr=0.0'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/data/augment.py:1850: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=75, p=0.0),\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/dog-pose/labels/val... 1703 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1703/1703 [00:01<00:00, 949.34it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/dog-pose/labels/val.cache\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING ‚ö†Ô∏è cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (2.1GB RAM): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1703/1703 [00:00<00:00, 2068.42it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to /content/drive/MyDrive/Dog_Gait_Demo/runs/train_accuracy_boost/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 87 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
            "Image sizes 768 train, 768 val\n",
            "Using 4 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/Dog_Gait_Demo/runs/train_accuracy_boost\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/data/augment.py:1850: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n",
            "  A.ImageCompression(quality_lower=75, p=0.0),\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/10       1.9G       1.06      8.865     0.4628     0.7435      1.785          5        768: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 847/847 [01:41<00:00,  8.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107/107 [01:15<00:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1703       1703      0.902      0.917      0.957      0.679      0.048      0.037     0.0119    0.00149\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/10      1.83G     0.9693      7.473     0.4177     0.6642      1.683          5        768: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 847/847 [01:13<00:00, 11.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107/107 [00:11<00:00,  9.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1703       1703      0.913      0.952      0.967      0.737     0.0651     0.0552     0.0152    0.00254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/10      1.83G     0.8904      6.851     0.4076     0.6016      1.597          5        768: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 847/847 [01:11<00:00, 11.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107/107 [00:11<00:00,  9.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1703       1703      0.905       0.95      0.963      0.728      0.142      0.127     0.0524    0.00846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/10      1.85G     0.8251      6.469     0.4038     0.5527      1.535          5        768: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 847/847 [01:10<00:00, 12.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107/107 [00:11<00:00,  9.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1703       1703      0.932       0.96      0.968      0.755      0.257      0.231     0.0994     0.0164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/10      1.82G      0.758      6.058     0.3989     0.5135      1.454          5        768: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 847/847 [01:10<00:00, 12.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107/107 [00:11<00:00,  9.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1703       1703      0.947      0.968      0.977      0.793      0.371       0.34      0.213     0.0397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/10      1.83G     0.6983      5.721     0.3945     0.4667      1.391          5        768: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 847/847 [01:10<00:00, 12.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107/107 [00:11<00:00,  9.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1703       1703      0.945      0.967       0.97      0.801      0.435      0.412       0.28     0.0562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/10      1.84G     0.6418      5.399     0.3913     0.4292      1.337          5        768: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 847/847 [01:10<00:00, 12.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107/107 [00:11<00:00,  9.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1703       1703      0.953      0.971      0.979      0.824      0.516      0.501      0.388     0.0846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/10      1.83G     0.5969      5.111     0.3911     0.4003      1.286          5        768: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 847/847 [01:10<00:00, 12.06it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107/107 [00:11<00:00,  9.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1703       1703      0.958      0.968      0.983      0.834      0.541      0.541      0.433     0.0984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/10      1.74G     0.5567      4.849     0.3898     0.3704      1.252          5        768: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 847/847 [01:10<00:00, 12.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107/107 [00:11<00:00,  9.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1703       1703      0.953      0.973      0.978      0.839      0.604      0.584       0.49      0.122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/10      1.74G     0.5375      4.684     0.3894     0.3587      1.224          5        768: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 847/847 [01:10<00:00, 12.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107/107 [00:11<00:00,  9.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1703       1703      0.949      0.981       0.98      0.849       0.62      0.589       0.51      0.132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "10 epochs completed in 0.258 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/Dog_Gait_Demo/runs/train_accuracy_boost/weights/last.pt, 20.7MB\n",
            "Optimizer stripped from /content/drive/MyDrive/Dog_Gait_Demo/runs/train_accuracy_boost/weights/best.pt, 20.7MB\n",
            "\n",
            "Validating /content/drive/MyDrive/Dog_Gait_Demo/runs/train_accuracy_boost/weights/best.pt...\n",
            "Ultralytics 8.3.0 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "YOLO11s-pose summary (fused): 257 layers, 10,149,963 parameters, 0 gradients, 24.0 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 107/107 [00:11<00:00,  9.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1703       1703      0.949      0.981       0.98      0.849      0.622       0.59      0.512      0.132\n",
            "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/Dog_Gait_Demo/runs/train_accuracy_boost\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Search for all best.pt files (including those in Drive)\n",
        "hits = list(Path(\"/content\").rglob(\"train_accuracy_boost\")) + list(Path(\"/content/drive/MyDrive\").rglob(\"train_accuracy_boost\"))\n",
        "for i, p in enumerate(hits):\n",
        "    print(i, p)\n"
      ],
      "metadata": {
        "id": "rpcMwWzUNn8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1Ô∏è‚É£ Clean up any stale mounts\n",
        "!fusermount -u /content/drive 2>/dev/null || true\n",
        "!rm -rf /content/drive\n",
        "\n",
        "# 2Ô∏è‚É£ Mount fresh\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 3Ô∏è‚É£ Make sure the destination folder exists in your *real* Drive\n",
        "!mkdir -p \"/content/drive/MyDrive/DogGaitWork_2025_Fall/Models\"\n",
        "\n",
        "# 4Ô∏è‚É£ Copy your training results (.pt files + logs)\n",
        "!cp -r /content/runs /content/drive/MyDrive/DogGaitWork_2025_Fall/Models/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoHjdb83LRYK",
        "outputId": "7590ff3d-5a23-4d46-97bf-bb7582eb3158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "cp: cannot stat '/content/runs': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Grab best or last weights from this run\n",
        "run_dir = sorted(Path(\"runs/pose\").glob(\"train_final*\"))[-1]\n",
        "w = run_dir / \"weights\" / \"best.pt\"\n",
        "if not w.exists():\n",
        "    w = run_dir / \"weights\" / \"last.pt\"\n",
        "print(\"Using weights:\", w)\n",
        "\n",
        "model = YOLO(str(w))\n",
        "\n",
        "# Use dataset val images for guaranteed dogs\n",
        "VAL_DIR = Path(\"datasets/dog-pose/images/val\")\n",
        "imgs = sorted(list(VAL_DIR.glob(\"*.jpg\")))[:6]\n",
        "assert imgs, f\"No images found in {VAL_DIR}\"\n",
        "\n",
        "preds = model.predict(source=[str(p) for p in imgs], imgsz=512, conf=0.10, save=False, verbose=False)\n",
        "\n",
        "OUT = Path(\"/content/Dog_Gait_Demo/overlays\"); OUT.mkdir(parents=True, exist_ok=True)\n",
        "saved = []\n",
        "for p, r in zip(imgs, preds):\n",
        "    im = r.plot(boxes=False, labels=False)   # force keypoints + skeleton drawn\n",
        "    out_path = OUT / f\"{p.stem}_pose.jpg\"\n",
        "    cv2.imwrite(str(out_path), im)\n",
        "    saved.append(out_path)\n",
        "\n",
        "print(\"Saved overlays:\")\n",
        "for s in saved:\n",
        "    print(\" -\", s)\n"
      ],
      "metadata": {
        "id": "7rk27LYQMciU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "217be0da-0e74-4c92-891a-9af210f56f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-458994085.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Grab best or last weights from this run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mrun_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"runs/pose\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_final*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"weights\"\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"best.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image\n",
        "for p in map(str, sorted((OUT).glob(\"*_pose.jpg\"))[:3]):\n",
        "    display(Image(filename=p))\n"
      ],
      "metadata": {
        "id": "M82H_eJmPnDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "VIDEO_PATH = \"/content/drive/MyDrive/Ginger_TornACL_Tendinitis_Movement.mp4\"\n",
        "print(\"Using:\", VIDEO_PATH)\n"
      ],
      "metadata": {
        "id": "fH9OUxyPvpWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Path to your Drive file\n",
        "video_path = Path(\"/content/drive/MyDrive/Ginger_TornACL_Tendinitis_Movement.mp4\")\n",
        "\n",
        "# Verify that it exists\n",
        "assert video_path.exists(), f\"Video not found: {video_path}\"\n",
        "\n",
        "print(\"Using:\", video_path)\n",
        "VIDEO_PATH = str(video_path)\n"
      ],
      "metadata": {
        "id": "8GpG04kbPnjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "\n",
        "w = \"runs/pose/train_final/weights/best.pt\"  # or last.pt\n",
        "model = YOLO(w)\n",
        "\n",
        "_ = model.predict(\n",
        "    source=VIDEO_PATH,\n",
        "    imgsz=512,\n",
        "    conf=0.10,\n",
        "    save=True,\n",
        "    vid_stride=1,\n",
        "    device=0\n",
        ")\n",
        "\n",
        "out_dir = sorted(Path(\"runs/pose\").glob(\"predict*\"))[-1]\n",
        "print(\"Overlaid video folder:\", out_dir)\n"
      ],
      "metadata": {
        "id": "bGGkTsDFU23H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "from IPython.display import Image, display\n",
        "IMAGE_PATH = \"/content/dog picture.jpg\"\n",
        "\n",
        "# Load trained model\n",
        "model = YOLO(\"runs/pose/train_final/weights/best.pt\")\n",
        "\n",
        "# Predict on your image\n",
        "results = model.predict(source=IMAGE_PATH, imgsz=640, conf=0.10, save=False, verbose=False)\n",
        "\n",
        "# Save overlayed result\n",
        "output_dir = Path(\"/content/Dog_Gait_Demo/overlays\")\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_path = output_dir / \"dog picture-pose.jpg\"\n",
        "\n",
        "im = results[0].plot(boxes=False, labels=False)\n",
        "cv2.imwrite(str(out_path), im)\n",
        "\n",
        "# Show result\n",
        "display(Image(filename=str(out_path)))\n",
        "print(\"Saved overlay:\", out_path)\n"
      ],
      "metadata": {
        "id": "VTp8pQxeU4jV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}